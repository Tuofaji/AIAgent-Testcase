"""
æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“

è°ƒå‚è¯´æ˜ï¼š
- å¦‚æœå‘ç°æ‰¹æ¬¡å¤„ç†ä»ç„¶å˜æ…¢ï¼Œå¯ä»¥è°ƒæ•´BATCH_CONFIGä¸­çš„å‚æ•°
- ç›‘æ§æ€§èƒ½æ€»ç»“è¾“å‡ºï¼Œè¯†åˆ«å“ªä¸ªæ‰¹æ¬¡å¤„ç†æ—¶é—´å¼‚å¸¸
- å¯¹äºå¤§é‡æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆï¼Œå»ºè®®é€‚å½“å¢åŠ max_batch_sizeå‡å°‘æ‰¹æ¬¡æ•°é‡
"""

import json
import os
import asyncio
from typing import List, Dict
import pandas as pd
import logfire
from openpyxl.reader.excel import load_workbook
from pydantic_ai import Agent, RunContext
from models import TestcaseAgentDeps
from llms import model
from openai import InternalServerError, APITimeoutError, RateLimitError

logfire.configure(token="your logfire token")

# æ‰¹æ¬¡å¤„ç†ä¼˜åŒ–é…ç½®
BATCH_CONFIG = {
    "max_retries": 1,  # å‡å°‘é‡è¯•æ¬¡æ•°ï¼Œé¿å…ç­‰å¾…æ—¶é—´ç´¯ç§¯
    "base_delay": 1,   # å‡å°‘åŸºç¡€å»¶è¿Ÿæ—¶é—´
    "max_batch_limit": 6,  # å‡å°‘æœ€å¤§æ‰¹æ¬¡æ•°é‡
    "performance_warning_threshold": 30,  # æ‰¹æ¬¡æ—¶é—´è­¦å‘Šé˜ˆå€¼ï¼ˆç§’ï¼‰
    "target_completion_ratio": 0.8,  # ç›®æ ‡å®Œæˆåº¦ï¼ˆ80%å³è®¤ä¸ºå®Œæˆï¼‰
}

class BatchPerformanceMonitor:
    """æ‰¹æ¬¡æ€§èƒ½ç›‘æ§å™¨"""
    def __init__(self):
        self.batch_times = []
        self.batch_sizes = []
        self.total_start_time = None
    
    def start_total_timing(self):
        """å¼€å§‹æ€»è®¡æ—¶"""
        import time
        self.total_start_time = time.time()
    
    def record_batch(self, batch_num: int, batch_size: int, elapsed_time: float):
        """è®°å½•æ‰¹æ¬¡æ€§èƒ½"""
        self.batch_times.append(elapsed_time)
        self.batch_sizes.append(batch_size)
        
        # è®¡ç®—å¹³å‡æ—¶é—´å’Œè¶‹åŠ¿
        if len(self.batch_times) > 1:
            avg_time = sum(self.batch_times) / len(self.batch_times)
            recent_avg = sum(self.batch_times[-3:]) / min(3, len(self.batch_times))
            
            if recent_avg > avg_time * 1.5:
                print(f"âš ï¸  è­¦å‘Šï¼šç¬¬ {batch_num} æ‰¹æ¬¡å¤„ç†æ—¶é—´ ({elapsed_time:.2f}s) æ˜æ˜¾è¶…å‡ºå¹³å‡æ—¶é—´ ({avg_time:.2f}s)")
            elif elapsed_time > BATCH_CONFIG["performance_warning_threshold"]:
                print(f"âš ï¸  è­¦å‘Šï¼šç¬¬ {batch_num} æ‰¹æ¬¡å¤„ç†æ—¶é—´è¿‡é•¿ ({elapsed_time:.2f}s)")
    
    def get_summary(self):
        """è·å–æ€§èƒ½æ€»ç»“"""
        if not self.batch_times:
            return "æ— æ‰¹æ¬¡æ•°æ®"
        
        import time
        total_time = time.time() - self.total_start_time if self.total_start_time else 0
        avg_batch_time = sum(self.batch_times) / len(self.batch_times)
        max_time = max(self.batch_times)
        min_time = min(self.batch_times)
        
        return f"""
ğŸ“Š æ‰¹æ¬¡æ€§èƒ½æ€»ç»“:
   - æ€»æ‰¹æ¬¡æ•°: {len(self.batch_times)}
   - æ€»è€—æ—¶: {total_time:.2f} ç§’
   - å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_batch_time:.2f} ç§’
   - æœ€å¿«æ‰¹æ¬¡: {min_time:.2f} ç§’
   - æœ€æ…¢æ‰¹æ¬¡: {max_time:.2f} ç§’
   - æ—¶é—´è¶‹åŠ¿: {'é€’å¢' if len(self.batch_times) > 2 and self.batch_times[-1] > self.batch_times[0] else 'ç¨³å®š'}
        """

# å…¨å±€æ€§èƒ½ç›‘æ§å™¨
performance_monitor = BatchPerformanceMonitor()

async def retry_with_backoff(func, max_retries=2, base_delay=1):
    """
    å¸¦æœ‰æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶
    Args:
        func: è¦é‡è¯•çš„å¼‚æ­¥å‡½æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆå‡å°‘é‡è¯•æ¬¡æ•°ï¼‰
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼ˆå‡å°‘åŸºç¡€å»¶è¿Ÿï¼‰
    Returns:
        å‡½æ•°æ‰§è¡Œç»“æœ
    """
    for attempt in range(max_retries + 1):
        try:
            return await func()
        except (InternalServerError, APITimeoutError, RateLimitError) as e:
            if attempt == max_retries:
                print(f"é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥: {e}")
                raise
            
            # ä½¿ç”¨çº¿æ€§é€€é¿è€Œä¸æ˜¯æŒ‡æ•°é€€é¿ï¼Œé¿å…åç»­æ‰¹æ¬¡ç­‰å¾…è¿‡ä¹…
            delay = base_delay * (attempt + 1)  # çº¿æ€§é€€é¿ï¼š1, 2, 3...
            print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}")
            print(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
            await asyncio.sleep(delay)
        except Exception as e:
            # éAPIç›¸å…³é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
            print(f"éAPIé”™è¯¯ï¼Œä¸é‡è¯•: {e}")
            raise

def optimize_requirements_text(requirements_list, max_length=1000):
    """
    ä¼˜åŒ–éœ€æ±‚æ–‡æœ¬é•¿åº¦ï¼Œé¿å…æç¤ºè¯è¿‡é•¿å¯¼è‡´è¶…æ—¶
    Args:
        requirements_list: éœ€æ±‚åˆ—è¡¨
        max_length: æœ€å¤§å­—ç¬¦é•¿åº¦
    Returns:
        ä¼˜åŒ–åçš„éœ€æ±‚æ–‡æœ¬
    """
    if not requirements_list:
        return "æ³¨æ„ï¼šæœªè·å–åˆ°å…·ä½“éœ€æ±‚åˆ—è¡¨ï¼Œè¯·åŸºäºå•†å“ç®¡ç†æ¨¡å—çš„å¸¸è§åŠŸèƒ½ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚"
    
    requirements_text = "å…·ä½“éœ€æ±‚åˆ—è¡¨ï¼š\n"
    current_length = len(requirements_text)
    
    for i, req in enumerate(requirements_list, 1):
        item_text = f"{i}. {req}\n"
        if current_length + len(item_text) > max_length:
            requirements_text += f"... (å…±{len(requirements_list)}æ¡éœ€æ±‚ï¼Œå·²æ˜¾ç¤ºå‰{i-1}æ¡)\n"
            break
        requirements_text += item_text
        current_length += len(item_text)
    
    return requirements_text

# åˆå§‹åŒ–AIä»£ç†
testcase_agent = Agent(model=model, deps_type=TestcaseAgentDeps)


@testcase_agent.system_prompt
async def generate_requirements(ctx: RunContext[TestcaseAgentDeps]) -> str:
    # è·å–å…·ä½“çš„éœ€æ±‚åˆ—è¡¨
    requirements_list = getattr(ctx.deps, 'requirements_list', [])
    
    # ä¼˜åŒ–éœ€æ±‚å†…å®¹å­—ç¬¦ä¸²ï¼Œé¿å…è¿‡é•¿å¯¼è‡´è¶…æ—¶
    requirements_text = optimize_requirements_text(requirements_list, max_length=800)
    
    return f'''
ä½ æ˜¯ä¸€åé«˜çº§æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚å’Œè¯´æ˜ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›æµ‹è¯•ç”¨ä¾‹ï¼Œæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹å¿…é¡»åŒ…å«8ä¸ªå­—æ®µï¼š
[
  {{
    "æ¨¡å—åç§°": "å…·ä½“æ¨¡å—åç§°ï¼ˆå¦‚ï¼šå•†å“å“ç‰Œã€å•†å“åˆ†ç±»ã€å•†å“ç®¡ç†ç­‰ï¼‰",
    "åŠŸèƒ½é¡¹": "å…·ä½“åŠŸèƒ½é¡¹ï¼ˆå¦‚ï¼šåˆ—è¡¨é¡µã€æ–°å¢ã€ä¿®æ”¹ã€å¯ç”¨ã€ç¦ç”¨ã€æŸ¥è¯¢ç­‰ï¼‰",
    "ç”¨ä¾‹è¯´æ˜": "è¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹è¯´æ˜ï¼ˆå¦‚ï¼šå•†å“å“ç‰Œé¡µé¢UIï¼ˆæ— æ•°æ®ï¼‰ã€æ­£ç¡®æ–°å¢å•†å“å“ç‰Œï¼ˆæ±‰å­—ï¼‰ç­‰ï¼‰",
    "å‰ç½®æ¡ä»¶": "æ‰§è¡Œæµ‹è¯•å‰éœ€è¦æ»¡è¶³çš„æ¡ä»¶ï¼ˆå¦‚ï¼šæ­£ç¡®è¿›å…¥å•†å“å“ç‰Œé¡µé¢ã€åˆ—è¡¨æ— æ•°æ®ç­‰ï¼‰",
    "è¾“å…¥": "æµ‹è¯•æ—¶éœ€è¦è¾“å…¥çš„æ•°æ®ï¼ˆå¦‚ï¼šå•†å“å“ç‰Œåç§°ï¼šè¿ªå¥¥ï¼Œæˆ–è€…ï¼šæ— ï¼‰",
    "æ‰§è¡Œæ­¥éª¤": "å…·ä½“çš„æ“ä½œæ­¥éª¤ï¼ˆå¦‚ï¼šç‚¹å‡»ã€æ–°å¢ã€‘æŒ‰é’®ã€æŸ¥çœ‹é¡µé¢UIç­‰ï¼‰",
    "é¢„æœŸç»“æœ": "æœŸæœ›çš„æµ‹è¯•ç»“æœï¼ˆè¯¦ç»†æè¿°é¢„æœŸçš„ç³»ç»Ÿå“åº”å’Œç•Œé¢å˜åŒ–ï¼‰",
    "é‡è¦ç¨‹åº¦": "é«˜/ä¸­/ä½"
  }}
]

æµ‹è¯•ç”¨ä¾‹è®¾è®¡è¦æ±‚ï¼š
1. è¦†ç›–UIç•Œé¢éªŒè¯ã€åŠŸèƒ½æ­£ç¡®æ€§ã€è¾“å…¥éªŒè¯ã€è¾¹ç•Œæ¡ä»¶ã€å¼‚å¸¸å¤„ç†ç­‰
2. åŒ…å«æ­£å¸¸æµç¨‹å’Œå¼‚å¸¸æµç¨‹çš„æµ‹è¯•åœºæ™¯
3. æ¯ä¸ªåŠŸèƒ½æ¨¡å—è¦æœ‰åˆ—è¡¨é¡µUIã€æ–°å¢ã€ä¿®æ”¹ã€å¯ç”¨/ç¦ç”¨ã€æŸ¥è¯¢ç­‰åŠŸèƒ½çš„æµ‹è¯•ç”¨ä¾‹
4. è¾“å…¥éªŒè¯è¦åŒ…å«ï¼šæ­£ç¡®è¾“å…¥ã€ä¸ºç©ºã€è¶…é•¿ã€é‡å¤ã€ç‰¹æ®Šå­—ç¬¦ã€è¾¹ç•Œå€¼ç­‰åœºæ™¯
5. é‡è¦ç¨‹åº¦æ ¹æ®åŠŸèƒ½é‡è¦æ€§å’Œç”¨æˆ·å½±å“ç¨‹åº¦è®¾å®š

{requirements_text}

ç”¨æˆ·è¦æ±‚ï¼š{ctx.deps.prompt}

è¯·ç”Ÿæˆè¯¦ç»†ã€ä¸“ä¸šã€å¯æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿æ ¼å¼å®Œå…¨ç¬¦åˆä¸Šè¿°JSONç»“æ„ã€‚
'''


async def write_test_cases_to_excel(test_cases: List[Dict], file_path: str):
    # ç¡®ä¿æµ‹è¯•ç”¨ä¾‹æŒ‰ç…§æ ‡å‡†å­—æ®µé¡ºåº
    standard_columns = ["æ¨¡å—åç§°", "åŠŸèƒ½é¡¹", "ç”¨ä¾‹è¯´æ˜", "å‰ç½®æ¡ä»¶", "è¾“å…¥", "æ‰§è¡Œæ­¥éª¤", "é¢„æœŸç»“æœ", "é‡è¦ç¨‹åº¦"]
    
    # é‡æ–°ç»„ç»‡æ•°æ®ï¼Œç¡®ä¿å­—æ®µé¡ºåºæ­£ç¡®
    standardized_cases = []
    for case in test_cases:
        standardized_case = {}
        for col in standard_columns:
            standardized_case[col] = case.get(col, "")
        standardized_cases.append(standardized_case)
    
    # å°†æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨è½¬æ¢ä¸ºDataFrameï¼ŒæŒ‡å®šåˆ—é¡ºåº
    df = pd.DataFrame(standardized_cases, columns=standard_columns)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.isfile(file_path):
        # åŠ è½½ç°æœ‰å·¥ä½œç°¿
        workbook = load_workbook(file_path)
        # é€‰æ‹©æ´»åŠ¨å·¥ä½œè¡¨
        sheet = workbook.active
        # å°†DataFrameè¿½åŠ åˆ°ç°æœ‰å·¥ä½œè¡¨
        for row in df.itertuples(index=False, name=None):
            sheet.append(row)
        # ä¿å­˜å·¥ä½œç°¿
        workbook.save(file_path)
    else:
        # å°†DataFrameå†™å…¥æ–°çš„Excelæ–‡ä»¶
        df.to_excel(file_path, index=False, engine='openpyxl')


def is_testcase_output_truncated(test_cases_data, expected_min_count: int = 3) -> bool:
    """
    æ£€æµ‹æµ‹è¯•ç”¨ä¾‹è¾“å‡ºæ˜¯å¦è¢«æˆªæ–­
    Args:
        test_cases_data: æµ‹è¯•ç”¨ä¾‹æ•°æ®
        expected_min_count: é¢„æœŸæœ€å°‘æ¡æ•°
    Returns:
        æ˜¯å¦è¢«æˆªæ–­
    """
    try:
        if isinstance(test_cases_data, str):
            # å¤„ç† markdown ä»£ç å—æ ¼å¼
            if test_cases_data.strip().startswith('```json'):
                # æå– json å†…å®¹
                lines = test_cases_data.strip().split('\n')
                json_lines = []
                in_json = False
                for line in lines:
                    if line.strip() == '```json':
                        in_json = True
                        continue
                    elif line.strip() == '```' and in_json:
                        break
                    elif in_json:
                        json_lines.append(line)
                test_cases_data = '\n'.join(json_lines)
            
            # æ£€æŸ¥JSONå­—ç¬¦ä¸²æ˜¯å¦å®Œæ•´
            test_cases = json.loads(test_cases_data)
        elif isinstance(test_cases_data, list):
            test_cases = test_cases_data
        else:
            return True
        
        if not test_cases or len(test_cases) == 0:
            return True
        
        # æ£€æŸ¥æœ€åä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹æ˜¯å¦å®Œæ•´
        last_case = test_cases[-1]
        required_fields = ["æ¨¡å—åç§°", "åŠŸèƒ½é¡¹", "ç”¨ä¾‹è¯´æ˜", "å‰ç½®æ¡ä»¶", "è¾“å…¥", "æ‰§è¡Œæ­¥éª¤", "é¢„æœŸç»“æœ", "é‡è¦ç¨‹åº¦"]
        
        for field in required_fields:
            if field not in last_case or not last_case[field]:
                return True
        
        return False
        
    except (json.JSONDecodeError, KeyError, IndexError):
        return True


def extract_testcase_data(test_cases_data):
    """
    æå–æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    Args:
        test_cases_data: åŸå§‹æ•°æ®
    Returns:
        è§£æåçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    """
    try:
        if isinstance(test_cases_data, str):
            # å¤„ç† markdown ä»£ç å—æ ¼å¼
            if '```json' in test_cases_data:
                # æå– json å†…å®¹
                lines = test_cases_data.split('\n')
                json_lines = []
                in_json = False
                for line in lines:
                    if '```json' in line:
                        in_json = True
                        continue
                    elif line.strip() == '```' and in_json:
                        break
                    elif in_json:
                        # å¤„ç†JavaScripté£æ ¼çš„æ³¨é‡Š
                        if '//' in line:
                            line = line.split('//')[0].rstrip()
                        if line.strip():  # åªæ·»åŠ éç©ºè¡Œ
                            json_lines.append(line)
                
                json_text = '\n'.join(json_lines)
                
                # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON
                json_text = json_text.strip()
                if json_text.endswith(','):
                    json_text = json_text[:-1]  # ç§»é™¤æœ«å°¾çš„é€—å·
                
                # å¦‚æœJSONçœ‹èµ·æ¥ä¸å®Œæ•´ï¼Œå°è¯•æ·»åŠ ç»“æŸæ‹¬å·
                if json_text.count('[') > json_text.count(']'):
                    json_text += ']'
                
                test_cases_data = json_text
            
            # å¦‚æœåŒ…å«å…¶ä»–æ–‡æœ¬ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            elif '[' in test_cases_data and ']' in test_cases_data:
                start = test_cases_data.find('[')
                end = test_cases_data.rfind(']') + 1
                test_cases_data = test_cases_data[start:end]
            
            # æ¸…ç†å¯èƒ½çš„JavaScriptæ³¨é‡Š
            lines = test_cases_data.split('\n')
            cleaned_lines = []
            for line in lines:
                if '//' in line:
                    line = line.split('//')[0].rstrip()
                if line.strip():
                    cleaned_lines.append(line)
            test_cases_data = '\n'.join(cleaned_lines)
            
            # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            test_cases_data = fix_json_format(test_cases_data)
            
            test_cases = json.loads(test_cases_data)
        elif isinstance(test_cases_data, list):
            test_cases = test_cases_data
        else:
            test_cases = getattr(test_cases_data, 'data', []) or []
        
        return test_cases
    except Exception as e:
        print(f"è§£ææµ‹è¯•ç”¨ä¾‹æ•°æ®å¤±è´¥: {e}")
        print(f"åŸå§‹æ•°æ®: {test_cases_data[:500]}...")  # æ‰“å°å‰500å­—ç¬¦ç”¨äºè°ƒè¯•
        return []


def fix_json_format(json_text):
    """
    ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
    """
    import re
    
    # ä¿®å¤ä¸å®Œæ•´çš„å­—ç¬¦ä¸²ï¼ˆç¼ºå°‘ç»“æŸå¼•å·ï¼‰
    lines = json_text.split('\n')
    fixed_lines = []
    
    for line in lines:
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸å®Œæ•´çš„å­—ç¬¦ä¸²å€¼
        if ':' in line and line.count('"') % 2 == 1:
            # å¦‚æœå¼•å·æ•°é‡æ˜¯å¥‡æ•°ï¼Œå¯èƒ½ç¼ºå°‘ç»“æŸå¼•å·
            if line.strip().endswith(',') or line.strip().endswith('}'):
                # åœ¨é€—å·æˆ–å¤§æ‹¬å·å‰æ·»åŠ å¼•å·
                line = re.sub(r'([^"]+)([,}])$', r'\1"\2', line)
            else:
                # åœ¨è¡Œæœ«æ·»åŠ å¼•å·
                line = line.rstrip() + '"'
        
        fixed_lines.append(line)
    
    json_text = '\n'.join(fixed_lines)
    
    # ä¿®å¤ä¸å®Œæ•´çš„å¯¹è±¡ï¼ˆç¼ºå°‘ç»“æŸå¤§æ‹¬å·ï¼‰
    open_braces = json_text.count('{')
    close_braces = json_text.count('}')
    
    if open_braces > close_braces:
        # æ·»åŠ ç¼ºå°‘çš„ç»“æŸå¤§æ‹¬å·
        missing_braces = open_braces - close_braces
        json_text = json_text.rstrip()
        if json_text.endswith(','):
            json_text = json_text[:-1]  # ç§»é™¤æœ«å°¾é€—å·
        json_text += '\n' + '  }' * missing_braces
    
    # ç¡®ä¿æ•°ç»„æ­£ç¡®é—­åˆ
    if json_text.count('[') > json_text.count(']'):
        json_text += ']'
    
    return json_text


async def run_agent(prompt: str, db_path: str = None, excel_path: str = None, filter: str = None, start_id: int = 1, target_count: int = 25, max_batch_size: int = 15, requirements_list: list = None) -> list:
    """
    è¿è¡Œæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“ï¼Œæ”¯æŒæ™ºèƒ½åˆ†æ‰¹å’Œé‡è¯•æœºåˆ¶
    Args:
        prompt: ç”¨æˆ·æç¤º
        db_path: æ•°æ®åº“è·¯å¾„
        excel_path: Excel è¾“å‡ºè·¯å¾„
        filter: è¿‡æ»¤æ¡ä»¶
        start_id: ID èµ·å§‹å€¼ï¼ˆç”¨äºæç¤ºæ¨¡å‹å½“å‰æ•°æ®èŒƒå›´ï¼‰
        target_count: ç›®æ ‡ç”Ÿæˆæ•°é‡
        max_batch_size: å•æ‰¹æœ€å¤§æ¡æ•°ï¼ˆç”¨äºåˆ†æ‰¹æ—¶ï¼‰
        requirements_list: å…·ä½“éœ€æ±‚åˆ—è¡¨
    Returns:
        ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    """
    import time
    start_time = time.time()
    
    # åˆå§‹åŒ–æ€§èƒ½ç›‘æ§
    performance_monitor.start_total_timing()
    
    # ç¬¬ä¸€æ¬¡å°è¯•ï¼šä¸€æ¬¡æ€§ç”Ÿæˆå…¨éƒ¨
    enhanced_prompt = f"{prompt}ï¼Œè¯·ç”Ÿæˆçº¦ {target_count} æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰é‡è¦åŠŸèƒ½ç‚¹ã€‚"
    
    # ä½¿ç”¨é‡è¯•æœºåˆ¶åŒ…è£…APIè°ƒç”¨
    async def first_attempt():
        return await testcase_agent.run(enhanced_prompt, deps=TestcaseAgentDeps(
            db_path=db_path,
            excel_path=excel_path,
            filter=filter,
            prompt=enhanced_prompt,
            total=target_count,
            batch_size=0,  # ä¸åˆ†æ‰¹
            requirements_list=requirements_list or []  # ä¼ é€’éœ€æ±‚åˆ—è¡¨
        ))
    
    try:
        result = await retry_with_backoff(first_attempt, max_retries=BATCH_CONFIG["max_retries"], base_delay=BATCH_CONFIG["base_delay"])
        print("testcase_agent.run result:", result)
        print("testcase_agent.run data:", result.data)
        
        # æå–æµ‹è¯•ç”¨ä¾‹æ•°æ®
        test_cases_data = result.data
        test_cases = extract_testcase_data(test_cases_data)
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æ•°é‡
        if len(test_cases) >= target_count * BATCH_CONFIG["target_completion_ratio"]:  # ä½¿ç”¨é…ç½®çš„å®Œæˆåº¦æ¯”ä¾‹
            elapsed = time.time() - start_time
            print(f"ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæˆï¼Œå…± {len(test_cases)} æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
            final_test_cases = test_cases[:target_count]  # æˆªå–åˆ°ç›®æ ‡æ•°é‡
            
            # å†™å…¥Excelæ–‡ä»¶
            if excel_path and final_test_cases:
                try:
                    await write_test_cases_to_excel(final_test_cases, excel_path)
                    print(f"æµ‹è¯•ç”¨ä¾‹å·²æˆåŠŸå†™å…¥Excelæ–‡ä»¶: {excel_path}")
                except Exception as e:
                    print(f"å†™å…¥Excelæ–‡ä»¶å¤±è´¥: {e}")
            
            return final_test_cases
        
        print(f"ä¸€æ¬¡æ€§ç”Ÿæˆäº† {len(test_cases)} æ¡ï¼Œæœªè¾¾åˆ°ç›®æ ‡ {target_count} æ¡ï¼Œå¯åŠ¨åˆ†æ‰¹æ¨¡å¼...")
        
    except Exception as e:
        print(f"ç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥: {e}")
        print("å¯åŠ¨é™çº§æ¨¡å¼ï¼šä½¿ç”¨æ›´ç®€å•çš„æç¤ºè¯é‡è¯•...")
        
        # é™çº§ç­–ç•¥ï¼šä½¿ç”¨æ›´ç®€å•çš„æç¤ºè¯
        simple_prompt = f"ç”Ÿæˆ {min(target_count, 10)} æ¡å•†å“ç®¡ç†æ¨¡å—çš„æµ‹è¯•ç”¨ä¾‹"
        
        async def fallback_attempt():
            return await testcase_agent.run(simple_prompt, deps=TestcaseAgentDeps(
                db_path=db_path,
                excel_path=excel_path,
                filter=filter,
                prompt=simple_prompt,
                total=min(target_count, 10),
                batch_size=0,
                requirements_list=[]  # é™çº§æ—¶ä¸ä¼ é€’éœ€æ±‚åˆ—è¡¨
            ))
        
        try:
            result = await retry_with_backoff(fallback_attempt, max_retries=BATCH_CONFIG["max_retries"], base_delay=BATCH_CONFIG["base_delay"])
            test_cases_data = result.data
            test_cases = extract_testcase_data(test_cases_data)
            elapsed = time.time() - start_time
            print(f"é™çº§æ¨¡å¼æˆåŠŸï¼Œç”Ÿæˆ {len(test_cases)} æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
            
            if excel_path and test_cases:
                try:
                    await write_test_cases_to_excel(test_cases, excel_path)
                    print(f"æµ‹è¯•ç”¨ä¾‹å·²æˆåŠŸå†™å…¥Excelæ–‡ä»¶: {excel_path}")
                except Exception as e:
                    print(f"å†™å…¥Excelæ–‡ä»¶å¤±è´¥: {e}")
            
            return test_cases
            
        except Exception as fallback_error:
            print(f"é™çº§æ¨¡å¼ä¹Ÿå¤±è´¥äº†: {fallback_error}")
            print("è¿”å›ç©ºåˆ—è¡¨")
            return []
    
    # åˆ†æ‰¹å¤„ç†æ¨¡å¼
    all_test_cases = test_cases.copy() if test_cases else []
    batch_num = 2  # ä»ç¬¬2æ‰¹å¼€å§‹ï¼Œå› ä¸ºç¬¬1æ‰¹å·²ç»ç”Ÿæˆäº†
    
    # ç´¯ç§¯æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ï¼Œæœ€åä¸€æ¬¡æ€§å†™å…¥Excelï¼Œé¿å…é¢‘ç¹I/O
    while len(all_test_cases) < target_count:
        batch_start_time = time.time()
        remaining = target_count - len(all_test_cases)
        batch_size = min(max_batch_size, remaining)
        
        # ç®€åŒ–æ‰¹æ¬¡æç¤ºè¯ï¼Œé¿å…å¤æ‚çš„ä¸Šä¸‹æ–‡ç´¯ç§¯
        batch_prompt = f"{prompt}ï¼Œè¯·ç”Ÿæˆ {batch_size} æ¡ä¸åŒçš„æµ‹è¯•ç”¨ä¾‹ã€‚"
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶åŒ…è£…æ‰¹æ¬¡è°ƒç”¨ï¼Œå‡å°‘é‡è¯•æ¬¡æ•°
        async def batch_attempt():
            return await testcase_agent.run(batch_prompt, deps=TestcaseAgentDeps(
                db_path=db_path,
                excel_path=excel_path,
                filter=filter,
                prompt=batch_prompt,
                total=batch_size,
                batch_size=batch_size,
                requirements_list=requirements_list or []  # ä¼ é€’éœ€æ±‚åˆ—è¡¨
            ))
        
        try:
            result = await retry_with_backoff(batch_attempt, max_retries=BATCH_CONFIG["max_retries"], base_delay=BATCH_CONFIG["base_delay"])
            test_cases_data = result.data
            batch_test_cases = extract_testcase_data(test_cases_data)
            
            batch_elapsed = time.time() - batch_start_time
            
            if not batch_test_cases:
                print(f"ç¬¬ {batch_num} æ‰¹æ¬¡æ— æœ‰æ•ˆæµ‹è¯•ç”¨ä¾‹ï¼Œç»“æŸåˆ†æ‰¹")
                break
            
            all_test_cases.extend(batch_test_cases)
            
            print(f"ç¬¬ {batch_num} æ‰¹æ¬¡å®Œæˆï¼Œç”Ÿæˆ {len(batch_test_cases)} æ¡ï¼Œç´¯è®¡ {len(all_test_cases)} æ¡ï¼Œè€—æ—¶ {batch_elapsed:.2f} ç§’")
            
            # è®°å½•æ‰¹æ¬¡æ€§èƒ½
            performance_monitor.record_batch(batch_num, len(batch_test_cases), batch_elapsed)
            
            # å¦‚æœè¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œç»“æŸ
            if len(all_test_cases) >= target_count:
                print(f"å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {target_count} æ¡ï¼Œç»“æŸåˆ†æ‰¹")
                break
            
            batch_num += 1
            
            # é˜²æ­¢æ— é™å¾ªç¯
            if batch_num > BATCH_CONFIG["max_batch_limit"]:  # ä½¿ç”¨é…ç½®çš„æœ€å¤§æ‰¹æ¬¡é™åˆ¶
                print("è¾¾åˆ°æœ€å¤§æ‰¹æ¬¡é™åˆ¶ï¼Œç»“æŸåˆ†æ‰¹")
                break
                
        except Exception as e:
            print(f"ç¬¬ {batch_num} æ‰¹æ¬¡å¤±è´¥: {e}ï¼Œç»“æŸåˆ†æ‰¹")
            break
    
    total_elapsed = time.time() - start_time
    print(f"åˆ†æ‰¹æ¨¡å¼å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {len(all_test_cases)} æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œæ€»è€—æ—¶ {total_elapsed:.2f} ç§’")
    
    # æ‰“å°æ€§èƒ½æ€»ç»“
    print(performance_monitor.get_summary())
    
    final_test_cases = all_test_cases[:target_count]  # æˆªå–åˆ°ç›®æ ‡æ•°é‡
    
    # ä¸€æ¬¡æ€§å†™å…¥Excelæ–‡ä»¶ï¼Œé¿å…é¢‘ç¹I/O
    if excel_path and final_test_cases:
        try:
            await write_test_cases_to_excel(final_test_cases, excel_path)
            print(f"æµ‹è¯•ç”¨ä¾‹å·²æˆåŠŸå†™å…¥Excelæ–‡ä»¶: {excel_path}")
        except Exception as e:
            print(f"å†™å…¥Excelæ–‡ä»¶å¤±è´¥: {e}")
    
    return final_test_cases

